
@inproceedings{he_deep_2016,
	title = {Deep {Residual} {Learning} for {Image} {Recognition}},
	doi = {10.1109/CVPR.2016.90},
	abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8× deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \& COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
	booktitle = {2016 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	month = jun,
	year = {2016},
	note = {ISSN: 1063-6919},
	keywords = {Neural networks, Complexity theory, Degradation, Image recognition, Image segmentation, Training, Visualization},
	pages = {770--778},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\osllo\\Zotero\\storage\\Z84NSPSX\\7780459.html:text/html;Submitted Version:C\:\\Users\\osllo\\Zotero\\storage\\BNJT275L\\He et al. - 2016 - Deep Residual Learning for Image Recognition.pdf:application/pdf},
}

@misc{noauthor_imagenette_2022,
	title = {Imagenette},
	copyright = {Apache-2.0},
	url = {https://github.com/fastai/imagenette},
	abstract = {A smaller subset of 10 easily classified classes from Imagenet, and a little more French},
	urldate = {2022-09-02},
	publisher = {fast.ai},
	month = sep,
	year = {2022},
	note = {original-date: 2019-03-06T01:58:45Z},
}

@misc{noauthor_cifar-10_nodate,
	title = {{CIFAR}-10 and {CIFAR}-100 datasets},
	url = {https://www.cs.toronto.edu/~kriz/cifar.html},
	urldate = {2022-09-02},
	file = {CIFAR-10 and CIFAR-100 datasets:C\:\\Users\\osllo\\Zotero\\storage\\DJS7IAAD\\cifar.html:text/html},
}

@misc{noauthor_mnist_nodate,
	title = {{MNIST} handwritten digit database, {Yann} {LeCun}, {Corinna} {Cortes} and {Chris} {Burges}},
	url = {http://yann.lecun.com/exdb/mnist/},
	urldate = {2022-08-23},
	file = {MNIST handwritten digit database, Yann LeCun, Corinna Cortes and Chris Burges:C\:\\Users\\osllo\\Zotero\\storage\\WYM2DS42\\mnist.html:text/html},
}

@misc{shrikumar_not_2017,
	title = {Not {Just} a {Black} {Box}: {Learning} {Important} {Features} {Through} {Propagating} {Activation} {Differences}},
	shorttitle = {Not {Just} a {Black} {Box}},
	url = {http://arxiv.org/abs/1605.01713},
	doi = {10.48550/arXiv.1605.01713},
	abstract = {Note: This paper describes an older version of DeepLIFT. See https://arxiv.org/abs/1704.02685 for the newer version. Original abstract follows: The purported "black box" nature of neural networks is a barrier to adoption in applications where interpretability is essential. Here we present DeepLIFT (Learning Important FeaTures), an efficient and effective method for computing importance scores in a neural network. DeepLIFT compares the activation of each neuron to its 'reference activation' and assigns contribution scores according to the difference. We apply DeepLIFT to models trained on natural images and genomic data, and show significant advantages over gradient-based methods.},
	urldate = {2022-08-23},
	publisher = {arXiv},
	author = {Shrikumar, Avanti and Greenside, Peyton and Shcherbina, Anna and Kundaje, Anshul},
	month = apr,
	year = {2017},
	note = {arXiv:1605.01713 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: 6 pages, 3 figures, this is an older version; see https://arxiv.org/abs/1704.02685 for the newer version},
	file = {arXiv Fulltext PDF:C\:\\Users\\osllo\\Zotero\\storage\\G95V459D\\Shrikumar et al. - 2017 - Not Just a Black Box Learning Important Features .pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\osllo\\Zotero\\storage\\IDVY7IET\\1605.html:text/html},
}

@inproceedings{sundararajan_axiomatic_2017,
	title = {Axiomatic {Attribution} for {Deep} {Networks}},
	url = {https://proceedings.mlr.press/v70/sundararajan17a.html},
	abstract = {We study the problem of attributing the prediction of a deep network to its input features, a problem previously studied by several other works. We identify two fundamental axioms—Sensitivity and Implementation Invariance that attribution methods ought to satisfy. We show that they are not satisfied by most known attribution methods, which we consider to be a fundamental weakness of those methods. We use the axioms to guide the design of a new attribution method called Integrated Gradients. Our method requires no modification to the original network and is extremely simple to implement; it just needs a few calls to the standard gradient operator. We apply this method to a couple of image models, a couple of text models and a chemistry model, demonstrating its ability to debug networks, to extract rules from a network, and to enable users to engage with models better.},
	language = {en},
	urldate = {2022-08-23},
	booktitle = {Proceedings of the 34th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Sundararajan, Mukund and Taly, Ankur and Yan, Qiqi},
	month = jul,
	year = {2017},
	note = {ISSN: 2640-3498},
	pages = {3319--3328},
	file = {Full Text PDF:C\:\\Users\\osllo\\Zotero\\storage\\J9CJHJNA\\Sundararajan et al. - 2017 - Axiomatic Attribution for Deep Networks.pdf:application/pdf},
}

@misc{springenberg_striving_2015,
	title = {Striving for {Simplicity}: {The} {All} {Convolutional} {Net}},
	shorttitle = {Striving for {Simplicity}},
	url = {http://arxiv.org/abs/1412.6806},
	doi = {10.48550/arXiv.1412.6806},
	abstract = {Most modern convolutional neural networks (CNNs) used for object recognition are built using the same principles: Alternating convolution and max-pooling layers followed by a small number of fully connected layers. We re-evaluate the state of the art for object recognition from small images with convolutional networks, questioning the necessity of different components in the pipeline. We find that max-pooling can simply be replaced by a convolutional layer with increased stride without loss in accuracy on several image recognition benchmarks. Following this finding -- and building on other recent work for finding simple network structures -- we propose a new architecture that consists solely of convolutional layers and yields competitive or state of the art performance on several object recognition datasets (CIFAR-10, CIFAR-100, ImageNet). To analyze the network we introduce a new variant of the "deconvolution approach" for visualizing features learned by CNNs, which can be applied to a broader range of network structures than existing approaches.},
	urldate = {2022-08-23},
	publisher = {arXiv},
	author = {Springenberg, Jost Tobias and Dosovitskiy, Alexey and Brox, Thomas and Riedmiller, Martin},
	month = apr,
	year = {2015},
	note = {arXiv:1412.6806 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: accepted to ICLR-2015 workshop track; no changes other than style},
	file = {arXiv Fulltext PDF:C\:\\Users\\osllo\\Zotero\\storage\\PTQ5MMT9\\Springenberg et al. - 2015 - Striving for Simplicity The All Convolutional Net.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\osllo\\Zotero\\storage\\UJKBJYTU\\1412.html:text/html},
}

@misc{simonyan_deep_2014,
	title = {Deep {Inside} {Convolutional} {Networks}: {Visualising} {Image} {Classification} {Models} and {Saliency} {Maps}},
	shorttitle = {Deep {Inside} {Convolutional} {Networks}},
	url = {http://arxiv.org/abs/1312.6034},
	doi = {10.48550/arXiv.1312.6034},
	abstract = {This paper addresses the visualisation of image classification models, learnt using deep Convolutional Networks (ConvNets). We consider two visualisation techniques, based on computing the gradient of the class score with respect to the input image. The first one generates an image, which maximises the class score [Erhan et al., 2009], thus visualising the notion of the class, captured by a ConvNet. The second technique computes a class saliency map, specific to a given image and class. We show that such maps can be employed for weakly supervised object segmentation using classification ConvNets. Finally, we establish the connection between the gradient-based ConvNet visualisation methods and deconvolutional networks [Zeiler et al., 2013].},
	urldate = {2022-08-22},
	publisher = {arXiv},
	author = {Simonyan, Karen and Vedaldi, Andrea and Zisserman, Andrew},
	month = apr,
	year = {2014},
	note = {arXiv:1312.6034 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:C\:\\Users\\osllo\\Zotero\\storage\\E3DSJCPC\\Simonyan et al. - 2014 - Deep Inside Convolutional Networks Visualising Im.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\osllo\\Zotero\\storage\\SQA9GEEP\\1312.html:text/html},
}

@article{lecun_convolutional_nodate,
	title = {Convolutional {Networks} for {Images}, {Speech}, and {Time}-{Series}},
	language = {en},
	author = {LeCun, Yann and Bengio, Yoshua and Laboratories, T Bell},
	pages = {14},
	file = {LeCun et al. - Convolutional Networks for Images, Speech, and Tim.pdf:C\:\\Users\\osllo\\Zotero\\storage\\AYXU5SUC\\LeCun et al. - Convolutional Networks for Images, Speech, and Tim.pdf:application/pdf},
}

@article{singh_think_2022,
	title = {Think positive: {An} interpretable neural network for image recognition},
	volume = {151},
	issn = {0893-6080},
	shorttitle = {Think positive},
	url = {https://www.sciencedirect.com/science/article/pii/S0893608022001125},
	doi = {10.1016/j.neunet.2022.03.034},
	abstract = {The COVID-19 pandemic is an ongoing pandemic and is placing additional burden on healthcare systems around the world. Timely and effectively detecting the virus can help to reduce the spread of the disease. Although, RT-PCR is still a gold standard for COVID-19 testing, deep learning models to identify the virus from medical images can also be helpful in certain circumstances. In particular, in situations when patients undergo routine X-rays and/or CT-scans tests but within a few days of such tests they develop respiratory complications. Deep learning models can also be used for pre-screening prior to RT-PCR testing. However, the transparency/interpretability of the reasoning process of predictions made by such deep learning models is essential. In this paper, we propose an interpretable deep learning model that uses positive reasoning process to make predictions. We trained and tested our model over the dataset of chest CT-scan images of COVID-19 patients, normal people and pneumonia patients. Our model gives the accuracy, precision, recall and F-score equal to 99.48\%, 0.99, 0.99 and 0.99, respectively.},
	language = {en},
	urldate = {2022-08-22},
	journal = {Neural Networks},
	author = {Singh, Gurmail},
	month = jul,
	year = {2022},
	keywords = {COVID-19, CT-scan, Interpretable, Pneumonia, Prototypes},
	pages = {178--189},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\osllo\\Zotero\\storage\\6AYGBYPE\\Singh - 2022 - Think positive An interpretable neural network fo.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\osllo\\Zotero\\storage\\GBDNMV9S\\S0893608022001125.html:text/html},
}

@misc{noauthor_imagenet_nodate,
	title = {{ImageNet}},
	url = {https://www.image-net.org/},
	urldate = {2022-08-22},
	file = {ImageNet:C\:\\Users\\osllo\\Zotero\\storage\\LE2EUFM7\\www.image-net.org.html:text/html},
}

@inproceedings{krizhevsky_imagenet_2012,
	title = {{ImageNet} {Classification} with {Deep} {Convolutional} {Neural} {Networks}},
	volume = {25},
	url = {https://papers.nips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html},
	abstract = {We trained a large, deep convolutional neural network to classify the 1.3 million high-resolution images in the LSVRC-2010 ImageNet training set into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 39.7{\textbackslash}\% and 18.9{\textbackslash}\% which is considerably better than the previous state-of-the-art results. The neural network, which has 60 million parameters and 500,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and two globally connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of convolutional nets. To reduce overfitting in the globally connected layers we employed a new regularization method that proved to be very effective.},
	urldate = {2022-08-22},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
	year = {2012},
	file = {Full Text PDF:C\:\\Users\\osllo\\Zotero\\storage\\T7FCIMVM\\Krizhevsky et al. - 2012 - ImageNet Classification with Deep Convolutional Ne.pdf:application/pdf},
}

@inproceedings{hooker_benchmark_2019,
	title = {A {Benchmark} for {Interpretability} {Methods} in {Deep} {Neural} {Networks}},
	volume = {32},
	url = {https://proceedings.neurips.cc/paper/2019/hash/fe4b8556000d0f0cae99daa5c5c5a410-Abstract.html},
	abstract = {We propose an empirical measure of the approximate accuracy of feature importance estimates in deep neural networks. Our results across several large-scale image classification datasets show that many popular interpretability methods produce estimates of feature importance that are not better than a random designation of feature importance. Only certain ensemble based approaches---VarGrad and SmoothGrad-Squared---outperform such a random assignment of importance. The manner of ensembling remains critical, we show that some approaches do no better then the underlying method but carry a far higher computational burden.},
	urldate = {2022-08-18},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Hooker, Sara and Erhan, Dumitru and Kindermans, Pieter-Jan and Kim, Been},
	year = {2019},
	file = {Full Text PDF:C\:\\Users\\osllo\\Zotero\\storage\\8FPGGC2Q\\Hooker et al. - 2019 - A Benchmark for Interpretability Methods in Deep N.pdf:application/pdf},
}

@inproceedings{ancona_towards_2018,
	title = {Towards better understanding of gradient-based attribution methods for {Deep} {Neural} {Networks}},
	url = {https://openreview.net/forum?id=Sy21R9JAW},
	urldate = {2022-08-18},
	booktitle = {6th {International} {Conference} on {Learning} {Representations}, {ICLR} 2018, {Vancouver}, {BC}, {Canada}, {April} 30 - {May} 3, 2018, {Conference} {Track} {Proceedings}},
	publisher = {OpenReview.net},
	author = {Ancona, Marco and Ceolini, Enea and Öztireli, Cengiz and Gross, Markus},
	year = {2018},
}

@article{petsiuk_rise_nodate,
	title = {{RISE}: {Randomized} {Input} {Sampling} for {Explanation} of {Black}-box {Models}},
	abstract = {Deep neural networks are being used increasingly to automate data analysis and decision making, yet their decision-making process is largely unclear and is difﬁcult to explain to the end users. In this paper, we address the problem of Explainable AI for deep neural networks that take images as input and output a class probability. We propose an approach called RISE that generates an importance map indicating how salient each pixel is for the model’s prediction. In contrast to white-box approaches that estimate pixel importance using gradients or other internal network state, RISE works on blackbox models. It estimates importance empirically by probing the model with randomly masked versions of the input image and obtaining the corresponding outputs. We compare our approach to state-of-the-art importance extraction methods using both an automatic deletion/insertion metric and a pointing metric based on human-annotated object segments. Extensive experiments on several benchmark datasets show that our approach matches or exceeds the performance of other methods, including white-box approaches.},
	language = {en},
	author = {Petsiuk, Vitali},
	pages = {13},
	file = {Petsiuk - RISE Randomized Input Sampling for Explanation of.pdf:C\:\\Users\\osllo\\Zotero\\storage\\XDI39SEY\\Petsiuk - RISE Randomized Input Sampling for Explanation of.pdf:application/pdf},
}

@misc{springenberg_striving_2015-1,
	title = {Striving for {Simplicity}: {The} {All} {Convolutional} {Net}},
	shorttitle = {Striving for {Simplicity}},
	url = {http://arxiv.org/abs/1412.6806},
	doi = {10.48550/arXiv.1412.6806},
	abstract = {Most modern convolutional neural networks (CNNs) used for object recognition are built using the same principles: Alternating convolution and max-pooling layers followed by a small number of fully connected layers. We re-evaluate the state of the art for object recognition from small images with convolutional networks, questioning the necessity of different components in the pipeline. We find that max-pooling can simply be replaced by a convolutional layer with increased stride without loss in accuracy on several image recognition benchmarks. Following this finding -- and building on other recent work for finding simple network structures -- we propose a new architecture that consists solely of convolutional layers and yields competitive or state of the art performance on several object recognition datasets (CIFAR-10, CIFAR-100, ImageNet). To analyze the network we introduce a new variant of the "deconvolution approach" for visualizing features learned by CNNs, which can be applied to a broader range of network structures than existing approaches.},
	urldate = {2022-08-18},
	publisher = {arXiv},
	author = {Springenberg, Jost Tobias and Dosovitskiy, Alexey and Brox, Thomas and Riedmiller, Martin},
	month = apr,
	year = {2015},
	note = {arXiv:1412.6806 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: accepted to ICLR-2015 workshop track; no changes other than style},
	file = {arXiv Fulltext PDF:C\:\\Users\\osllo\\Zotero\\storage\\KI9GBIHN\\Springenberg et al. - 2015 - Striving for Simplicity The All Convolutional Net.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\osllo\\Zotero\\storage\\R4TMJUUM\\1412.html:text/html},
}

@inproceedings{zeiler_visualizing_2014,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Visualizing and {Understanding} {Convolutional} {Networks}},
	isbn = {978-3-319-10590-1},
	doi = {10.1007/978-3-319-10590-1_53},
	abstract = {Large Convolutional Network models have recently demonstrated impressive classification performance on the ImageNet benchmark Krizhevsky et al. [18]. However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we explore both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classifier. Used in a diagnostic role, these visualizations allow us to find model architectures that outperform Krizhevsky et al on the ImageNet classification benchmark. We also perform an ablation study to discover the performance contribution from different model layers. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets.},
	language = {en},
	booktitle = {Computer {Vision} – {ECCV} 2014},
	publisher = {Springer International Publishing},
	author = {Zeiler, Matthew D. and Fergus, Rob},
	editor = {Fleet, David and Pajdla, Tomas and Schiele, Bernt and Tuytelaars, Tinne},
	year = {2014},
	keywords = {Convolutional Neural Network, Input Image, Pixel Space, Stochastic Gradient Descent, Training Image},
	pages = {818--833},
	file = {Full Text PDF:C\:\\Users\\osllo\\Zotero\\storage\\Q6IBMRLG\\Zeiler and Fergus - 2014 - Visualizing and Understanding Convolutional Networ.pdf:application/pdf},
}

@article{smilkov_smoothgrad_nodate,
	title = {{SmoothGrad}: removing noise by adding noise},
	abstract = {Explaining the output of a deep network remains a challenge. In the case of an image classiﬁer, one type of explanation is to identify pixels that strongly inﬂuence the ﬁnal decision. A starting point for this strategy is the gradient of the class score function with respect to the input image. This gradient can be interpreted as a sensitivity map, and there are several techniques that elaborate on this basic idea. This paper makes two contributions: it introduces SMOOTHGRAD, a simple method that can help visually sharpen gradient-based sensitivity maps, and it discusses lessons in the visualization of these maps. We publish the code for our experiments and a website with our results.},
	language = {en},
	author = {Smilkov, Daniel and Thorat, Nikhil and Kim, Been and Viégas, Fernanda and Wattenberg, Martin},
	pages = {10},
	file = {Smilkov et al. - SmoothGrad removing noise by adding noise.pdf:C\:\\Users\\osllo\\Zotero\\storage\\PN4IYK9X\\Smilkov et al. - SmoothGrad removing noise by adding noise.pdf:application/pdf},
}

@inproceedings{adebayo_sanity_2018,
	title = {Sanity {Checks} for {Saliency} {Maps}},
	volume = {31},
	url = {https://papers.nips.cc/paper/2018/hash/294a8ed24b1ad22ec2e7efea049b8737-Abstract.html},
	abstract = {Saliency methods have emerged as a popular tool to highlight features in an input
deemed relevant for the prediction of a learned model. Several saliency methods
have been proposed, often guided by visual appeal on image data. In this work, we
propose an actionable methodology to evaluate what kinds of explanations a given
method can and cannot provide. We find that reliance, solely, on visual assessment
can be misleading. Through extensive experiments we show that some existing
saliency methods are independent both of the model and of the data generating
process. Consequently, methods that fail the proposed tests are inadequate for
tasks that are sensitive to either data or model, such as, finding outliers in the data,
explaining the relationship between inputs and outputs that the model learned,
and debugging the model. We interpret our findings through an analogy with
edge detection in images, a technique that requires neither training data nor model.
Theory in the case of a linear model and a single-layer convolutional neural network
supports our experimental findings.},
	urldate = {2022-08-18},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Adebayo, Julius and Gilmer, Justin and Muelly, Michael and Goodfellow, Ian and Hardt, Moritz and Kim, Been},
	year = {2018},
	file = {Full Text PDF:C\:\\Users\\osllo\\Zotero\\storage\\W2UHPF67\\Adebayo et al. - 2018 - Sanity Checks for Saliency Maps.pdf:application/pdf},
}
